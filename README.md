# ğŸŒ©ï¸ Real-time Weather Data ETL Pipeline

This project demonstrates a real-time weather data ETL pipeline that:
- Ingests live weather data using the OpenWeatherMap API via a FastAPI service
- Streams data into Apache Kafka
- Processes the stream with Apache Spark Structured Streaming
- Stores the cleaned and structured output into SQLite

It is fully containerized using Docker and can be easily extended to production-scale systems.
# ğŸ§° Tools & Technologies Used

| Tool              | Role                                                        |
|-------------------|-------------------------------------------------------------|
| OpenWeatherMap API| Source of real-time weather data                            |
| FastAPI           | Lightweight REST API to fetch and push weather data to Kafka|
| Apache Kafka      | Real-time messaging system to stream data                   |
| Apache Spark      | Structured Streaming for real-time processing               |
| SQLite            | Lightweight DB to store processed weather data              |
| Docker            | Containerized deployment of all services                    |
| Bitnami Spark     | Prebuilt Spark image for simplified setup                   |
| Python            | Language used in API, producer, and Spark job logic         |

# ğŸ“ Project Structure

weather-data-pipeline/
â”œâ”€â”€ docker-compose.yml               # Orchestrates all services
â”œâ”€â”€ kafka_producer/
â”‚   â””â”€â”€ weather_producer.py          # Producer script pushing data into Kafka
â”œâ”€â”€ spark/
â”‚   â”œâ”€â”€ spark_processor.py           # Spark job processing Kafka data
â”‚   â””â”€â”€ sqlite_db.py                 # Handles SQLite insertions
â”œâ”€â”€ fast_api/
â”‚   â””â”€â”€ api_server.py                # FastAPI endpoint fetching weather from OpenWeather
â”œâ”€â”€ alerts_db.py                     # Script to manually check SQLite data
â”œâ”€â”€ requirements.txt                 # Python dependencies
â””â”€â”€ README.md

# âš™ï¸ How the Pipeline Works

1. ğŸŒ FastAPI hits OpenWeatherMap API (e.g., for Kolkata) and returns weather data as JSON.
2. ğŸ“¨ That data is published to Kafka topic `weather_topic` using a Python producer.
3. ğŸ” Spark Structured Streaming listens to `weather_topic`, parses, transforms, and filters the data.
4. ğŸ§± Processed data is stored in a local SQLite database.
5. ğŸ“‹ You can inspect the DB using `alerts_db.py` or any SQLite GUI.

Skills: Python â€¢ Kafka â€¢ Spark â€¢ SQL â€¢ FastAPI â€¢ Docker â€¢ Streaming Pipelines 

Create Topic for kafka consumer
 docker exec -it kafka bash
 kafka-topics --create --topic my-topic --bootstrap-server localhost:9092 --partitions 3 --replication-factor 1
 kafka-console-producer --topic my-topic  --bootstrap-server localhost:9092
 kafka-console-consumer --topic weather_topic  --bootstrap-server localhost:9092
